{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_LU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PUWxxCLmj47"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo9nxGCumskv"
      },
      "source": [
        "import pandas as pd\r\n",
        "import os\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GP5O_87mu1v"
      },
      "source": [
        "pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLmRb0fdmwW4"
      },
      "source": [
        "import os\r\n",
        "from tokenizers.models import BPE\r\n",
        "from tokenizers import Tokenizer\r\n",
        "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\r\n",
        "from tokenizers.normalizers import NFKC, Sequence\r\n",
        "from tokenizers.pre_tokenizers import ByteLevel\r\n",
        "from tokenizers.trainers import BpeTrainer as BpeTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3KY01X8mzQG"
      },
      "source": [
        "class BPE_token(object):\r\n",
        "  def __init__(self):\r\n",
        "    self.tokenizer=Tokenizer(BPE())\r\n",
        "    self.tokenizer.normalizer=Sequence([NFKC()])\r\n",
        "    self.tokenizer.pre_tokenizer=ByteLevel()\r\n",
        "    self.tokenizer.decoder=ByteLevelDecoder()\r\n",
        "  def bpe_train(self,paths):\r\n",
        "    trainer=BpeTrainer(vocab_size= 50257,show_progress=True,initial_alphabet=ByteLevel.alphabet(),special_tokens=['[BEYT_B]','[BEYT_E]','[MESRA_SEP]','[POEM_B]','[PAD]','[UNK]','[MSK]','[NO_SEP]','[POEM_E]'])\r\n",
        "    self.tokenizer.train(trainer,paths)\r\n",
        "  def save_tokenizer(self,location,prefix=None):\r\n",
        "    if not os.path.exists(location):\r\n",
        "      os.makedirs(location)\r\n",
        "    self.tokenizer.model.save(location,prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2D-CjL7roM8"
      },
      "source": [
        "به دلیل جلوگیری از شلوغ شدن کد قبلاً کدی که با آن تگ ها را به دیتاست اضافه می کردم حذف کردم و به همین دلیل کد آخرین روش اضافه کردن تگ ها در دیتاست موجود نیست! \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ1oFg5DuiL9"
      },
      "source": [
        "from pathlib import Path\n",
        "import os# the folder 'text' contains all the files\n",
        "paths = [str(x) for x in Path(\"drive/MyDrive/poemDatasets_Second/train/\").glob(\"**/*.txt\")]\n",
        "tokenizer = BPE_token()# train the tokenizer model\n",
        "tokenizer.bpe_train(paths)# saving the tokenized data in our specified folder \n",
        "save_path = 'drive/MyDrive/tokenized_data_Second/train/'\n",
        "tokenizer.save_tokenizer(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCMjVGZym0-O",
        "outputId": "eb2e2c1e-7617-4cd6-a911-36baf53a7198"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBCMo_Oju6lC",
        "outputId": "426a906f-211a-475d-a0ef-322b490d4d9f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wwEElvUm2jg",
        "outputId": "8c114b04-a5c0-4370-cad2-13659a5be872"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from transformers import GPT2Config, TFGPT2LMHeadModel, GPT2Tokenizer# loading tokenizer from the saved model path\r\n",
        "save_path = 'drive/MyDrive/tokenized_data_Fourth/'\r\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(save_path)\r\n",
        "tokenizer.add_special_tokens({\r\n",
        "    'bos_token':'[POEM_B]',\r\n",
        "    'eos_token':'[POEM_E]',\r\n",
        "   \"unk_token\":'[UNK]',\r\n",
        "   \"pad_token\":'[PAD]',\r\n",
        "   \"mask_token\":'[MSK]'\r\n",
        "})# creating the configurations from which the mo\r\n",
        "\r\n",
        "config = GPT2Config(\r\n",
        "  vocab_size=tokenizer.vocab_size,\r\n",
        "  bos_token_id=tokenizer.bos_token_id,\r\n",
        "  eos_token_id=tokenizer.eos_token_id,\r\n",
        "  pad_token_id=tokenizer.pad_token_id,\r\n",
        "  unk_token_id=tokenizer.unk_token_id,\r\n",
        "  mask_token_id=tokenizer.mask_token_id,\r\n",
        "  n_positions=512,\r\n",
        "  n_ctx= 512,\r\n",
        "  n_embd=768\r\n",
        "\r\n",
        ")# creating the model\r\n",
        "model = TFGPT2LMHeadModel(config)\r\n",
        "print(model.config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 3,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 8,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"mask_token_id\": 6,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"pad_token_id\": 4,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.3.3\",\n",
            "  \"unk_token_id\": 5,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrFiVqiEVEe"
      },
      "source": [
        "class my_dictionary(dict): \r\n",
        "  \r\n",
        "    # __init__ function \r\n",
        "    def __init__(self): \r\n",
        "        self = dict()      \r\n",
        "    # Function to add key:value \r\n",
        "    def add(self, key, value):\r\n",
        "        if key in self.keys(): \r\n",
        "          self[key].append( value)\r\n",
        "        else:\r\n",
        "          self[key]=[]\r\n",
        "          self[key].append( value)\r\n",
        "  \r\n",
        "# Main Function \r\n",
        "dict_poems_train = my_dictionary() \r\n",
        "all_poems=[]\r\n",
        "all_poems_hAndF=[];\r\n",
        "with open('drive/MyDrive/poemDatasets_Fourth/test/AllPoemsTest.txt', \"r\", encoding='utf-8') as f:\r\n",
        "  all_poems=f.readlines()\r\n",
        "for i in range(0,len(all_poems)-1 ,2):\r\n",
        "  all_poems[i]=all_poems[i].replace('\\n','')\r\n",
        "  all_poems[i+1]=all_poems[i+1].replace('\\n','')\r\n",
        "  dict_poems_train.add(all_poems[i],all_poems[i+1])\r\n",
        "  if all_poems[i]=='حافظ' or all_poems[i]=='فردوسی':\r\n",
        "    all_poems_hAndF.append(all_poems[i+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_3mB78OEv_K",
        "outputId": "016352d0-777e-4ea4-b031-4f09e60f2a6d"
      },
      "source": [
        "dict_poems_train.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['حافظ', 'فردوسی', 'مولوی', 'نظامی', 'سعدی', 'پروین اعتصامی', 'عطار', 'سنایی', 'وحشی', 'فرخی سیستانی', 'اوحدی', 'انوری', 'عراقی', 'صائب تبریزی', 'شیخ محمود شبستری', 'هاتف اصفهانی', 'منوچهری', 'باباطاهر', 'محتشم کاشانی', 'شیخ بهایی', 'سیف فرغانی', 'فروغی بسطامی', 'امیرخسرو دهلوی', 'رودکی', 'فخرالدین اسعد گرگانی', 'سلمان ساوجی', 'رهی معیری', 'اقبال لاهوری', 'کسایی', 'عرفی شیرازی', 'رضی\\u200cالدین آرتیمانی', 'هلالی جغتایی', 'شاه نعمت\\u200cالله ولی', 'شهریار', 'اسدی توسی', 'خیام', 'شاطرعباس صبوحی', 'ملک\\u200cالشعرای بهار', 'مسعود سعد سلمان', 'جامی', 'رشیدالدین میبدی', 'عنصری', 'سعدالدین وراوینی', 'کمال\\u200cالدین اسماعیل', 'حکیم نزاری', 'قدسی مشهدی', 'کمال خجندی', 'صامت بروجردی', 'نیما یوشیج', 'احمد شاملو', 'سهراب سپهری', 'فروغ فرخزاد', 'سیمین بهبهانی', 'مهدی اخوان ثالث', 'محمدحسن بارق شفیعی', 'عبدالواسع جبلی', 'عبدالقهّار عاصی', 'فریدون مشیری', 'سایه', 'نادر نادرپور', 'امام خمینی', 'احمد پروین', 'نجمه زارع', 'سید حمیدرضا برقعی', 'مولانا خالد نقشبندی', 'داوود ملک\\u200cزاده', 'شیوا فرازمند', 'ایرج میرزا'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhMSSagEg73"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "sumLen=0\r\n",
        "numPoems=0\r\n",
        "poems=''\r\n",
        "for poem in all_poems_hAndF:\r\n",
        "  poems+=poem+' '\r\n",
        "string_tokenized = tokenizer.encode(poems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFIHlAgUshnO"
      },
      "source": [
        "from pathlib import Path\r\n",
        "single_string = ''\r\n",
        "paths1 = [str(x) for x in Path(\"drive/MyDrive/poemDatasets_Fourth/train/\").glob(\"**/*.txt\")]\r\n",
        "k=0\r\n",
        "for filename in paths1: \r\n",
        "   with open(filename, \"r\", encoding='utf-8') as f:\r\n",
        "    x = f.read()  \r\n",
        "    single_string += x \r\n",
        "string_tokenized = tokenizer.encode(single_string)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS3N1QlAnDq6",
        "outputId": "35ca48b6-9340-4b91-c9f7-f542c3a2a2c8"
      },
      "source": [
        "examples = []\r\n",
        "block_size = 200\r\n",
        "BATCH_SIZE = 12\r\n",
        "BUFFER_SIZE = 1000\r\n",
        "for i in range(0, len(string_tokenized) - block_size + 1, block_size):\r\n",
        "  examples.append(string_tokenized[i:i + block_size])\r\n",
        "inputs, labels = [], []\r\n",
        "for ex in examples:\r\n",
        "  inputs.append(ex[:-1])\r\n",
        "  labels.append(ex[1:])\r\n",
        "print(np.shape(inputs))\r\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((inputs,labels))\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs,labels))\r\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62288, 199)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQj7sFqxnKjm",
        "outputId": "ca8c0482-a46d-4292-9ff2-6a6a824f33e2"
      },
      "source": [
        "# defining our optimizer\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)# definining our loss function\r\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)# defining our metric which we want to observe\r\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')# compiling the model\r\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])\r\n",
        "# model.build(np.shape(dataset))\r\n",
        "print(model.config)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 3,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 8,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"mask_token_id\": 6,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"pad_token_id\": 4,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.3.3\",\n",
            "  \"unk_token_id\": 5,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50000\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sQ13ecbnMXv",
        "outputId": "d692c748-fb42-4c01-d392-571fcb9a6762"
      },
      "source": [
        "num_epoch = 10\r\n",
        "checkpoint_path = \"drive/MyDrive/LU-HW_HF/cp-{epoch:04d}.ckpt\"\r\n",
        "\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "print(checkpoint_dir)\r\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\r\n",
        "print(latest)\r\n",
        "model.load_weights(latest)\r\n",
        "batch_size = 12\r\n",
        "# Create a callback that saves the model's weights every 5 epochs\r\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "#     filepath=checkpoint_path, \r\n",
        "#     verbose=1, \r\n",
        "#     save_weights_only=True,\r\n",
        "#     save_freq=5190)\r\n",
        "# model.save_weights(checkpoint_path.format(epoch=0))\r\n",
        "# history = model.fit(dataset,epochs=num_epoch,callbacks=[cp_callback])\r\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/LU-HW_HF\n",
            "drive/MyDrive/LU-HW_HF/cp-0010.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBya9iuQxSL8"
      },
      "source": [
        "num_epoch = 6\r\n",
        "checkpoint_path = \"drive/MyDrive/training_10/cp-{epoch:04d}.ckpt\"\r\n",
        "\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "print(checkpoint_dir)\r\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\r\n",
        "print(latest)\r\n",
        "model.load_weights(latest)\r\n",
        "batch_size = 12\r\n",
        "\r\n",
        "# Create a callback that saves the model's weights every 5 epochs\r\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_path, \r\n",
        "    verbose=1, \r\n",
        "    save_weights_only=True,\r\n",
        "    save_freq=8305)\r\n",
        "model.save_weights(checkpoint_path.format(epoch=11))\r\n",
        "# outputs= model.\r\n",
        "# history = model.fit(dataset,batch_size=12,epochs=num_epoch,callbacks=[cp_callback])\r\n",
        "history = model.fit(dataset,epochs=num_epoch,callbacks=[cp_callback])\r\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdA4sOFcn_qu"
      },
      "source": [
        "class my_dictionary(dict): \r\n",
        "  \r\n",
        "    # __init__ function \r\n",
        "    def __init__(self): \r\n",
        "        self = dict()      \r\n",
        "    # Function to add key:value \r\n",
        "    def add(self, key, value):\r\n",
        "        if key in self.keys(): \r\n",
        "          self[key].append( value)\r\n",
        "        else:\r\n",
        "          self[key]=[]\r\n",
        "          self[key].append( value)\r\n",
        "  \r\n",
        "# Main Function \r\n",
        "dict_poems_train = my_dictionary() \r\n",
        "all_poems=[]\r\n",
        "all_poems_hAndF=[];\r\n",
        "with open('drive/MyDrive/poemDatasets_Fourth/test/AllPoemsTest.txt', \"r\", encoding='utf-8') as f:\r\n",
        "  all_poems=f.readlines()\r\n",
        "for i in range(0,len(all_poems)-1 ,2):\r\n",
        "  all_poems[i]=all_poems[i].replace('\\n','')\r\n",
        "  all_poems[i+1]=all_poems[i+1].replace('\\n','')\r\n",
        "  dict_poems_train.add(all_poems[i],all_poems[i+1])\r\n",
        "  if all_poems[i]=='حافظ' or all_poems[i]=='فردوسی':\r\n",
        "    all_poems_hAndF.append(all_poems[i+1])\r\n",
        "\r\n",
        "import csv\r\n",
        "with open('drive/MyDrive/poems_dataset_test.csv', mode='w' , encoding='utf-8') as poem_file:\r\n",
        "    poem_writer = csv.writer(poem_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL )\r\n",
        "    count=0  \r\n",
        "    poem_writer.writerow(['col1','col2','m-b','poet'])  \r\n",
        "    for poet in dict_poems_train.keys():   \r\n",
        "      poems=dict_poems_train[poet]\r\n",
        "      for poem in poems:\r\n",
        "        beyts=poem.replace('[POEM_B]','').replace('[POEM_E]','').replace('[BEYT_B]','').split('[BEYT_E]')\r\n",
        "        # print(beyts)\r\n",
        "        for i in range(0,len(beyts)-1,1):\r\n",
        "          if len(beyts[i+1])>1 and np.random.rand()<0.035:\r\n",
        "             poem_writer.writerow([beyts[i],beyts[i+1],'b',poet])  \r\n",
        "        for beyt in beyts:\r\n",
        "          if len(beyt)>1:\r\n",
        "            sep_word='[MESRA_SEP]'\r\n",
        "            if '[NO_SEP]'in beyt:\r\n",
        "              sep_word='[NO_SEP]'\r\n",
        "            mesras=beyt.split(sep_word)\r\n",
        "            for j in range(0,len(mesras)-1,1):\r\n",
        "              if np.random.rand()<0.035:\r\n",
        "                poem_writer.writerow([mesras[j],mesras[j+1],'m',poet])\r\n",
        "        count+=1\r\n",
        "        # if count>1:\r\n",
        "        #   break\r\n",
        "        \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "ATuY865lnwfn",
        "outputId": "48113f83-90e8-4b2b-b5a4-26155f77e16b"
      },
      "source": [
        "import pandas as pd\r\n",
        "data=pd.read_csv('drive/MyDrive/poems_dataset_test.csv')\r\n",
        "\r\n",
        "poets=data['poet'].unique()\r\n",
        "\r\n",
        "data[data['m-b']=='m'][data['poet']=='حافظ']\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col1</th>\n",
              "      <th>col2</th>\n",
              "      <th>m-b</th>\n",
              "      <th>poet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>با لاله رخی و گوشه بستانی</td>\n",
              "      <td>عیشی بود آن نه حد هر سلطانی</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>جز نقش تو در نظر نیامد ما را</td>\n",
              "      <td>جز کوی تو رهگذر نیامد ما را</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>مشنو سخن خصم که بنشین و مرو</td>\n",
              "      <td>بشنو ز من این نکته که برخیز و بیا</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>در باغ چو شد باد صبا دایهٔ گل</td>\n",
              "      <td>بربست مشاطه‌وار پیرایهٔ گل</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>آصف عهد زمان جان جهان تورانشاه</td>\n",
              "      <td>که در این مزرعه جز دانهٔ خیرات نکشت</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6260</th>\n",
              "      <td>شیدای دو آهوی شکار اندازت</td>\n",
              "      <td>صد چون من و صد هزار چون استادم</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6262</th>\n",
              "      <td>خانم! منم که تلخ ترین واژه ی شما م</td>\n",
              "      <td>من،این کنیز گمشده در «چار راه» بخت</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6263</th>\n",
              "      <td>دستم نگیر زخمی ام از سر نوشت خود</td>\n",
              "      <td>آری  نشسته  بر دل  من آه...! آه بخت</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6264</th>\n",
              "      <td>زنغمهٔ غم و اندوه ِ هق هق‌ات ای اشک</td>\n",
              "      <td>به لحظه لحظهٔ شعرم ترانه می‌باری</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>تو مثلِ پاکیِ آبی، ببار بر تن من</td>\n",
              "      <td>که من صداقتِ سرسبزِ شالی‌ام با تو</td>\n",
              "      <td>m</td>\n",
              "      <td>حافظ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3276 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        col1  ...  poet\n",
              "0                 با لاله رخی و گوشه بستانی   ...  حافظ\n",
              "2              جز نقش تو در نظر نیامد ما را   ...  حافظ\n",
              "3               مشنو سخن خصم که بنشین و مرو   ...  حافظ\n",
              "4             در باغ چو شد باد صبا دایهٔ گل   ...  حافظ\n",
              "5            آصف عهد زمان جان جهان تورانشاه   ...  حافظ\n",
              "...                                      ...  ...   ...\n",
              "6260              شیدای دو آهوی شکار اندازت   ...  حافظ\n",
              "6262     خانم! منم که تلخ ترین واژه ی شما م   ...  حافظ\n",
              "6263       دستم نگیر زخمی ام از سر نوشت خود   ...  حافظ\n",
              "6264    زنغمهٔ غم و اندوه ِ هق هق‌ات ای اشک   ...  حافظ\n",
              "6265       تو مثلِ پاکیِ آبی، ببار بر تن من   ...  حافظ\n",
              "\n",
              "[3276 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euktzzYOoKE7",
        "outputId": "a19c0b25-e554-4004-adea-682a6627ff91"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "dict_bleu_mesra={}\r\n",
        "with open('drive/MyDrive/poems_bleu.txt', mode='w' , encoding='utf-8') as poem_bleu:\r\n",
        "  for poet in poets:\r\n",
        "    if poet=='حافظ' or poet=='فردوسی':\r\n",
        "      data_ref=data[data['m-b']=='b'][data['poet']==poet]\r\n",
        "      print(poet)\r\n",
        "      poem_bleu.write(poet+'\\n')\r\n",
        "      sum_bleu=0\r\n",
        "      num_dat=0\r\n",
        "      for i in range(len(data_ref)):\r\n",
        "        row=data_ref.iloc[i]\r\n",
        "        input=row['col1']\r\n",
        "        input=input[0:len(input)-1]\r\n",
        "        input= input.replace('[MESRA_SEP]','')\r\n",
        "        reference=row['col2'].replace('[MESRA_SEP]','').replace('  ',' ').replace('  ',' ').split(' ')\r\n",
        "        input_ids = tokenizer.encode(input, return_tensors='tf')# getting out output\r\n",
        "        # print(input_ids)\r\n",
        "        # print(input_ids.shape[1])\r\n",
        "        beam_output = model.generate(\r\n",
        "          input_ids,\r\n",
        "          max_length = input_ids.shape[1]*2 ,\r\n",
        "          num_beams = 5,\r\n",
        "          temperature = 0.3,\r\n",
        "          no_repeat_ngram_size=3,\r\n",
        "          num_return_sequences=5\r\n",
        "        )\r\n",
        "        # print(input_ids.shape[1]*3)\r\n",
        "        candidate=tokenizer.decode(beam_output[0]).replace(input,'').replace('[BEYT_E]',' ').replace('[BEYT_B]',' ').replace('[MESRA_SEP]',' ').replace('  ',' ').replace('\\t','').replace('[BEYT_B]','').replace('[BEYT_E]','').split(' ')\r\n",
        "        ref1=[]\r\n",
        "        for ref in reference:\r\n",
        "          if len(ref)>0:\r\n",
        "            ref1.append(ref)\r\n",
        "        cand1=[]\r\n",
        "        for cand in candidate:\r\n",
        "          if len(cand)>0:\r\n",
        "            cand1.append(cand)\r\n",
        "        score=sentence_bleu([ref1],cand1)\r\n",
        "        # print(input)\r\n",
        "        # print(ref1)\r\n",
        "        # print(cand1)\r\n",
        "        # print(score)\r\n",
        "        sum_bleu+=score\r\n",
        "        num_dat+=1\r\n",
        "        if num_dat%10==0:\r\n",
        "          print(num_dat)\r\n",
        "          print(sum_bleu)\r\n",
        "          poem_bleu.write(str(score))\r\n",
        "          poem_bleu.write('\\n')\r\n",
        "      poem_bleu.write(str(score))\r\n",
        "      poem_bleu.write('\\n')\r\n",
        "      dict_bleu_mesra[poet]= sum_bleu/num_dat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "حافظ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "0.5992632158286924\n",
            "20\n",
            "3.9021436914959096\n",
            "30\n",
            "6.817306216646528\n",
            "40\n",
            "7.7540177416162\n",
            "50\n",
            "10.041475675666925\n",
            "60\n",
            "11.17396234662747\n",
            "70\n",
            "12.60480015694009\n",
            "80\n",
            "13.682627564165278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "90\n",
            "15.271161881148414\n",
            "100\n",
            "16.287986698769974\n",
            "110\n",
            "18.41442210301647\n",
            "120\n",
            "20.232408916179402\n",
            "130\n",
            "21.615942253521354\n",
            "140\n",
            "23.47276923017248\n",
            "150\n",
            "24.91666790005504\n",
            "160\n",
            "27.74027280721701\n",
            "170\n",
            "30.245280570939066\n",
            "180\n",
            "32.6309900805944\n",
            "190\n",
            "34.64189551561537\n",
            "200\n",
            "36.395037188328295\n",
            "210\n",
            "39.16388266510243\n",
            "220\n",
            "40.91870874308225\n",
            "230\n",
            "43.17949528561903\n",
            "240\n",
            "45.50713620536615\n",
            "250\n",
            "46.742617492000804\n",
            "260\n",
            "49.33128214902821\n",
            "270\n",
            "52.19130533910188\n",
            "280\n",
            "54.04221563837093\n",
            "290\n",
            "55.82174978871104\n",
            "300\n",
            "57.03312345486662\n",
            "310\n",
            "59.446553469036104\n",
            "320\n",
            "61.934523516277125\n",
            "330\n",
            "63.62148075767613\n",
            "340\n",
            "66.19609437093025\n",
            "350\n",
            "68.62326710833852\n",
            "360\n",
            "70.92540133388532\n",
            "370\n",
            "72.05935179970022\n",
            "380\n",
            "73.04544335005819\n",
            "390\n",
            "75.97808538288888\n",
            "400\n",
            "77.73078671995049\n",
            "410\n",
            "79.89196530745394\n",
            "420\n",
            "82.2974132640226\n",
            "430\n",
            "84.38317727604336\n",
            "440\n",
            "85.62926505272897\n",
            "450\n",
            "87.49139478883896\n",
            "460\n",
            "89.53607168521381\n",
            "470\n",
            "92.74015045319088\n",
            "480\n",
            "95.54096485141156\n",
            "490\n",
            "97.60318130173378\n",
            "500\n",
            "100.26567611329858\n",
            "510\n",
            "102.33953777304023\n",
            "520\n",
            "104.6873318480809\n",
            "530\n",
            "107.46420061395311\n",
            "540\n",
            "109.72027424442564\n",
            "550\n",
            "111.64256439459147\n",
            "560\n",
            "114.39065600776092\n",
            "570\n",
            "117.12923559327082\n",
            "580\n",
            "119.49880105278879\n",
            "590\n",
            "122.00372059420107\n",
            "600\n",
            "124.05555665290193\n",
            "610\n",
            "125.88182085120998\n",
            "620\n",
            "128.26583644991297\n",
            "630\n",
            "128.89212094618952\n",
            "640\n",
            "131.38349499633242\n",
            "650\n",
            "133.08732523634382\n",
            "660\n",
            "134.73340829135333\n",
            "670\n",
            "137.5510764240272\n",
            "680\n",
            "138.41630950159873\n",
            "690\n",
            "140.68929517443465\n",
            "700\n",
            "142.55461897338117\n",
            "710\n",
            "143.67082643564882\n",
            "720\n",
            "144.9205112540508\n",
            "730\n",
            "146.53732578760642\n",
            "740\n",
            "148.7806028042945\n",
            "750\n",
            "149.88875886667205\n",
            "760\n",
            "151.38263748252984\n",
            "770\n",
            "152.80549966902285\n",
            "780\n",
            "154.33548488509362\n",
            "790\n",
            "156.17221976233355\n",
            "800\n",
            "158.5530370475113\n",
            "810\n",
            "160.82371029784866\n",
            "820\n",
            "161.91224758300274\n",
            "830\n",
            "163.62736619937266\n",
            "840\n",
            "165.0879740140816\n",
            "850\n",
            "165.59032455732563\n",
            "860\n",
            "167.4299400929377\n",
            "870\n",
            "169.41482506863866\n",
            "880\n",
            "172.33370897527413\n",
            "890\n",
            "175.65403525098733\n",
            "900\n",
            "177.13444576849966\n",
            "910\n",
            "179.3331079608148\n",
            "920\n",
            "180.93588917370678\n",
            "930\n",
            "183.02029437365476\n",
            "940\n",
            "184.68796813017835\n",
            "950\n",
            "186.1136479104292\n",
            "960\n",
            "187.16630859076417\n",
            "970\n",
            "189.9277130622884\n",
            "980\n",
            "193.06956278289877\n",
            "990\n",
            "194.7420209485187\n",
            "1000\n",
            "196.16946909161558\n",
            "1010\n",
            "197.17598926395627\n",
            "1020\n",
            "199.9698203224134\n",
            "1030\n",
            "201.3768297455441\n",
            "1040\n",
            "204.85692781742463\n",
            "1050\n",
            "206.90404782693759\n",
            "1060\n",
            "209.07711902407456\n",
            "1070\n",
            "211.986069450985\n",
            "1080\n",
            "213.25740572946867\n",
            "1090\n",
            "216.31369111279244\n",
            "1100\n",
            "218.79397588681582\n",
            "1110\n",
            "221.57697441182714\n",
            "1120\n",
            "223.9665127831638\n",
            "1130\n",
            "225.79524619148046\n",
            "1140\n",
            "228.67628117575498\n",
            "1150\n",
            "229.9449439473615\n",
            "1160\n",
            "230.80095343126894\n",
            "1170\n",
            "232.74233472928498\n",
            "1180\n",
            "235.46574046972145\n",
            "1190\n",
            "238.97592414921155\n",
            "1200\n",
            "240.8321287285495\n",
            "1210\n",
            "241.5008690335259\n",
            "1220\n",
            "242.60991752902717\n",
            "1230\n",
            "245.292927255019\n",
            "1240\n",
            "248.26324286139499\n",
            "1250\n",
            "251.16675573580088\n",
            "1260\n",
            "252.90873818295765\n",
            "1270\n",
            "256.3974780062326\n",
            "1280\n",
            "258.438058566887\n",
            "1290\n",
            "260.15456181143406\n",
            "1300\n",
            "262.15788705554235\n",
            "1310\n",
            "263.1201442833107\n",
            "1320\n",
            "264.0760217724964\n",
            "1330\n",
            "266.3964280444531\n",
            "1340\n",
            "268.2270111679537\n",
            "1350\n",
            "270.5511670364795\n",
            "1360\n",
            "272.71733289829183\n",
            "1370\n",
            "273.5943317348951\n",
            "1380\n",
            "274.69673262902734\n",
            "1390\n",
            "275.28458866335507\n",
            "1400\n",
            "277.1854322609352\n",
            "1410\n",
            "279.42858810944443\n",
            "1420\n",
            "281.69173786157455\n",
            "1430\n",
            "283.9254216765799\n",
            "1440\n",
            "285.48513357386486\n",
            "1450\n",
            "287.1011844533358\n",
            "1460\n",
            "288.69600161201487\n",
            "1470\n",
            "291.83864717504713\n",
            "1480\n",
            "294.09519361822663\n",
            "1490\n",
            "295.44757572216605\n",
            "1500\n",
            "297.5034343356173\n",
            "1510\n",
            "298.9071010699813\n",
            "1520\n",
            "302.0698261211294\n",
            "1530\n",
            "303.95948512146975\n",
            "1540\n",
            "304.93839716288267\n",
            "1550\n",
            "305.94399803937614\n",
            "1560\n",
            "308.297402647205\n",
            "1570\n",
            "309.41330413203735\n",
            "1580\n",
            "311.6287846778242\n",
            "1590\n",
            "314.8666223307285\n",
            "1600\n",
            "317.73795051516487\n",
            "1610\n",
            "319.32655152003355\n",
            "1620\n",
            "322.76281035533606\n",
            "1630\n",
            "324.455208986357\n",
            "1640\n",
            "327.25828788373803\n",
            "1650\n",
            "329.4497988249203\n",
            "1660\n",
            "332.1832747725473\n",
            "1670\n",
            "334.5530705667304\n",
            "1680\n",
            "335.9011370525996\n",
            "1690\n",
            "338.725974344919\n",
            "1700\n",
            "341.39571098606166\n",
            "1710\n",
            "344.42152297508613\n",
            "1720\n",
            "347.5312322688678\n",
            "1730\n",
            "349.35141446828806\n",
            "1740\n",
            "351.03292201437205\n",
            "1750\n",
            "352.7337015151907\n",
            "1760\n",
            "354.2616516188801\n",
            "1770\n",
            "355.7508386330814\n",
            "1780\n",
            "358.8740180143128\n",
            "1790\n",
            "359.55918329849084\n",
            "1800\n",
            "362.05052729797137\n",
            "1810\n",
            "364.21628746265475\n",
            "1820\n",
            "365.69319270199\n",
            "1830\n",
            "367.45413137854325\n",
            "1840\n",
            "369.34588634295983\n",
            "1850\n",
            "371.79191670706217\n",
            "1860\n",
            "373.8490664683844\n",
            "1870\n",
            "375.31555524034735\n",
            "1880\n",
            "377.1985960297142\n",
            "1890\n",
            "378.95961193348273\n",
            "1900\n",
            "380.5571200137683\n",
            "1910\n",
            "382.6642621135014\n",
            "1920\n",
            "385.2928648542822\n",
            "1930\n",
            "389.12754994951865\n",
            "1940\n",
            "391.5879765258273\n",
            "1950\n",
            "394.08099320774943\n",
            "1960\n",
            "396.8974391706456\n",
            "1970\n",
            "398.8153550457822\n",
            "1980\n",
            "400.3764776739924\n",
            "1990\n",
            "402.33810989013176\n",
            "2000\n",
            "404.8770488854648\n",
            "2010\n",
            "408.0681064998227\n",
            "2020\n",
            "410.8941187073595\n",
            "2030\n",
            "412.6039845566654\n",
            "2040\n",
            "414.3231640467741\n",
            "2050\n",
            "415.5374690846171\n",
            "2060\n",
            "416.9679102730225\n",
            "2070\n",
            "418.08225280885864\n",
            "2080\n",
            "421.1792727333606\n",
            "2090\n",
            "423.95426273379985\n",
            "2100\n",
            "424.75763429383113\n",
            "2110\n",
            "427.14641273230575\n",
            "2120\n",
            "430.0755585070124\n",
            "2130\n",
            "430.79917431596687\n",
            "2140\n",
            "433.10106520198894\n",
            "2150\n",
            "435.3832246218946\n",
            "2160\n",
            "438.47075178875065\n",
            "2170\n",
            "441.08800802489003\n",
            "2180\n",
            "443.3417978652613\n",
            "2190\n",
            "445.1320589662109\n",
            "2200\n",
            "447.08015601091034\n",
            "2210\n",
            "448.7775848686366\n",
            "2220\n",
            "449.70540919398417\n",
            "2230\n",
            "451.60872539330364\n",
            "2240\n",
            "454.754996196992\n",
            "2250\n",
            "456.1925867115208\n",
            "2260\n",
            "459.18235244708256\n",
            "2270\n",
            "461.12041279246944\n",
            "2280\n",
            "462.7488988350703\n",
            "2290\n",
            "465.5976214221156\n",
            "2300\n",
            "467.3935194979895\n",
            "2310\n",
            "469.9230902937524\n",
            "2320\n",
            "472.04751366510266\n",
            "2330\n",
            "475.049815141563\n",
            "2340\n",
            "478.46618406476637\n",
            "2350\n",
            "479.7433080615931\n",
            "2360\n",
            "483.5565095366158\n",
            "2370\n",
            "484.8904310101051\n",
            "2380\n",
            "486.88404352131494\n",
            "2390\n",
            "488.85327989194855\n",
            "2400\n",
            "491.2435112618417\n",
            "2410\n",
            "493.41548227657523\n",
            "2420\n",
            "496.67560724410424\n",
            "2430\n",
            "498.24786066055356\n",
            "2440\n",
            "500.63495197714616\n",
            "2450\n",
            "501.05298239006424\n",
            "2460\n",
            "502.57601683600944\n",
            "2470\n",
            "504.7792631560423\n",
            "2480\n",
            "507.4277035685862\n",
            "2490\n",
            "509.9235715727187\n",
            "2500\n",
            "512.3537013683274\n",
            "2510\n",
            "514.346398939853\n",
            "2520\n",
            "517.3456797242671\n",
            "2530\n",
            "518.6883203705777\n",
            "2540\n",
            "520.9680704293643\n",
            "2550\n",
            "521.6219531425731\n",
            "2560\n",
            "523.8559956359862\n",
            "2570\n",
            "525.9691476397404\n",
            "2580\n",
            "528.5350559007638\n",
            "2590\n",
            "530.3299906371947\n",
            "2600\n",
            "531.78604611511\n",
            "2610\n",
            "532.9633453102093\n",
            "2620\n",
            "535.0621047360185\n",
            "2630\n",
            "537.1097588054754\n",
            "2640\n",
            "540.4439853397038\n",
            "2650\n",
            "542.1926833563228\n",
            "2660\n",
            "544.7981838860015\n",
            "2670\n",
            "547.2414708366787\n",
            "2680\n",
            "548.7362843968764\n",
            "2690\n",
            "551.3756168950564\n",
            "2700\n",
            "552.7532990373193\n",
            "2710\n",
            "554.5030692019074\n",
            "2720\n",
            "556.4930615576716\n",
            "2730\n",
            "559.4078462574703\n",
            "2740\n",
            "559.6340141796168\n",
            "2750\n",
            "562.7051841158018\n",
            "2760\n",
            "566.062422806751\n",
            "2770\n",
            "568.0786148784816\n",
            "2780\n",
            "569.5798367917687\n",
            "2790\n",
            "572.5236397458642\n",
            "2800\n",
            "574.6070189602552\n",
            "2810\n",
            "576.3860415906939\n",
            "2820\n",
            "577.5397300845078\n",
            "2830\n",
            "580.1533352917584\n",
            "2840\n",
            "582.5721966332449\n",
            "2850\n",
            "584.0225598654869\n",
            "2860\n",
            "585.6792837530533\n",
            "2870\n",
            "587.1059719769065\n",
            "2880\n",
            "590.3400790947302\n",
            "2890\n",
            "591.97228922002\n",
            "2900\n",
            "593.9875797951786\n",
            "2910\n",
            "597.7774775136726\n",
            "2920\n",
            "599.873953401803\n",
            "2930\n",
            "601.7511349035141\n",
            "2940\n",
            "603.8592360937724\n",
            "2950\n",
            "606.3283924563043\n",
            "2960\n",
            "610.440391545247\n",
            "2970\n",
            "612.1390812909639\n",
            "2980\n",
            "614.2284107843896\n",
            "2990\n",
            "617.9919921810488\n",
            "3000\n",
            "619.6651266200998\n",
            "3010\n",
            "621.493635881431\n",
            "3020\n",
            "623.0387308766957\n",
            "3030\n",
            "624.9925541340458\n",
            "3040\n",
            "626.642097020205\n",
            "3050\n",
            "629.3226594792043\n",
            "3060\n",
            "631.6856385739861\n",
            "3070\n",
            "633.1000661183604\n",
            "3080\n",
            "635.3463994077485\n",
            "3090\n",
            "637.1652726785491\n",
            "3100\n",
            "639.9034481955866\n",
            "3110\n",
            "641.5695628821215\n",
            "3120\n",
            "642.876387621294\n",
            "3130\n",
            "644.291130693824\n",
            "3140\n",
            "646.2683542361176\n",
            "3150\n",
            "647.1412678772549\n",
            "3160\n",
            "647.7378248655359\n",
            "3170\n",
            "650.233354138676\n",
            "3180\n",
            "652.7887890792452\n",
            "3190\n",
            "654.6813809897632\n",
            "3200\n",
            "656.3767331081161\n",
            "3210\n",
            "658.9460247945273\n",
            "3220\n",
            "660.5157525688711\n",
            "3230\n",
            "662.6648797327377\n",
            "3240\n",
            "665.7236191720748\n",
            "3250\n",
            "667.8076073057739\n",
            "3260\n",
            "671.655284690555\n",
            "3270\n",
            "673.1473227465956\n",
            "3280\n",
            "675.4978607322095\n",
            "3290\n",
            "677.4956908497504\n",
            "3300\n",
            "679.4316969749632\n",
            "3310\n",
            "682.1541006842009\n",
            "3320\n",
            "684.0341226698712\n",
            "3330\n",
            "686.5422675552344\n",
            "فردوسی\n",
            "10\n",
            "1.6159636021685062\n",
            "20\n",
            "4.534331077250178\n",
            "30\n",
            "6.193857905634152\n",
            "40\n",
            "7.742236480868148\n",
            "50\n",
            "8.234199031235015\n",
            "60\n",
            "9.956727116247707\n",
            "70\n",
            "11.52437507761166\n",
            "80\n",
            "13.376162282179898\n",
            "90\n",
            "15.555939799542442\n",
            "100\n",
            "16.42330863590921\n",
            "110\n",
            "17.298871217224015\n",
            "120\n",
            "19.743902632613217\n",
            "130\n",
            "22.248707322568045\n",
            "140\n",
            "23.01801726076848\n",
            "150\n",
            "25.041316196247433\n",
            "160\n",
            "25.8511080816593\n",
            "170\n",
            "28.4890172559504\n",
            "180\n",
            "29.34640587413123\n",
            "190\n",
            "30.169646597277982\n",
            "200\n",
            "31.432172948002798\n",
            "210\n",
            "32.216048162904514\n",
            "220\n",
            "32.59453514871789\n",
            "230\n",
            "34.71807657950943\n",
            "240\n",
            "37.1441032686942\n",
            "250\n",
            "38.892090940390204\n",
            "260\n",
            "39.0605145140883\n",
            "270\n",
            "40.703891788867224\n",
            "280\n",
            "41.94256890847173\n",
            "290\n",
            "43.749819053534175\n",
            "300\n",
            "46.162499344464926\n",
            "310\n",
            "48.42855136747208\n",
            "320\n",
            "49.67311202303862\n",
            "330\n",
            "50.96513427885674\n",
            "340\n",
            "52.46947776208798\n",
            "350\n",
            "53.107806578530145\n",
            "360\n",
            "55.14540382289481\n",
            "370\n",
            "56.706380370036456\n",
            "380\n",
            "58.11878659467463\n",
            "390\n",
            "59.05639371031642\n",
            "400\n",
            "59.472986410259736\n",
            "410\n",
            "61.15434360011461\n",
            "420\n",
            "63.88584251314281\n",
            "430\n",
            "64.82914841801622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inlM-OSEtXBt",
        "outputId": "225691fa-383c-4aa9-dace-7600b2746895"
      },
      "source": [
        "import numpy as np\r\n",
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "for poet in poets:\r\n",
        "  if poet=='فردوسی':\r\n",
        "    data_ref=data[data['m-b']=='b'][data['poet']==poet]\r\n",
        "    print(poet)\r\n",
        "    print(len(data_ref))\r\n",
        "    for i in range(len(data_ref)):\r\n",
        "      if np.random.rand() < 0.02:\r\n",
        "        row=data_ref.iloc[i]\r\n",
        "        input=row['col1']\r\n",
        "        input=input[0:len(input)-1]\r\n",
        "        input= input.replace('[MESRA_SEP]','')\r\n",
        "        reference=row['col2']\r\n",
        "        input_ids = tokenizer.encode(input, return_tensors='tf')# getting out output\r\n",
        "        # print(input_ids)\r\n",
        "        # print(input_ids.shape[1])\r\n",
        "        beam_output = model.generate(\r\n",
        "          input_ids,\r\n",
        "          max_length = input_ids.shape[1]*2 ,\r\n",
        "          num_beams = 5,\r\n",
        "          temperature = 0.3,\r\n",
        "          no_repeat_ngram_size=3,\r\n",
        "          num_return_sequences=5\r\n",
        "        )\r\n",
        "      # print(input_ids.shape[1]*3)\r\n",
        "        print(input)\r\n",
        "        print(reference)\r\n",
        "        print('outputs: ')\r\n",
        "        for out in beam_output:\r\n",
        "          candidate=tokenizer.decode(out)\r\n",
        "          print(candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "فردوسی\n",
            "266\n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان\n",
            "  گرانمایه سیندخت را پیش خواند [MESRA_SEP]  بسی خوب گفتار با او براند \n",
            "outputs: \n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان شد [MESRA_SEP] چو از مادر به خواب آمد ، ز درد\n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان شد [MESRA_SEP] چو ماه فلک، خورشید رخشان، خرم و\n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان شد [MESRA_SEP] چو چشم مست او، امید وصال یار من\n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان شد [MESRA_SEP] چو ماه فلک، خورشید رخشان، خرم از\n",
            "  چو مهراب شد شاد و روشن روان   لبش گشت خندان و دل شادمان شد [MESRA_SEP] چو از مادر به خواب آمد ، به آهنگ\n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه\n",
            "  پشیمان بشد زان کجا گفته بود [MESRA_SEP]  بیهودگی مغزش آشفته بود \n",
            "outputs: \n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه روزن [MESRA_SEP] به تیر و تیغ و تیر و\n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه [MESRA_SEP] به کردار دل اهل دلان شد ، به\n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه گفت : [MESRA_SEP] برادران را ما چنین گفت و\n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه [MESRA_SEP] به کردار دل اهل دلان شد ،گشای\n",
            "  چو بشنید گفتار گودرز شاه   بدانست کاو دارد آیین و راه [MESRA_SEP] به کردار دل شاه و به کردار تن\n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج\n",
            "  ز گنجش زبرجد نثار آورید [MESRA_SEP]  بسی گوهر شاهوار آورید \n",
            "outputs: \n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج [MESRA_SEP] بشد خاموش و گفت : ای شهریار واحسینا [\n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج [MESRA_SEP] بشد خاموش و گفت : ای شهریار واحسینا!\n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج [MESRA_SEP] سر دوشیزگان غیب بنگر جای خالی خالی خالی از عبیر\n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج [MESRA_SEP] سر دوشیزگان غیب بنگر باز کن یاویل پر از\n",
            "  ببوسید و بنهاد بر سرش تاج   به کرسی شد از نامور تخت عاج [MESRA_SEP] سر او را به تاج شهریار افسر دارا شکوه [\n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت\n",
            "  بهای جوالی همی‌داشتم [MESRA_SEP]  به پیش سپاه تو بگذاشتم \n",
            "outputs: \n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت آتش [MESRA_SEP] سوخت قلب سپاه تیره ی من\n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت با دست ، من که : من برنگ تو با دست خود\n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت [MESRA_SEP] که تو در برابر سرو جویباری،\n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت [MESRA_SEP] که تو در برابر چشمی نشسته ای\n",
            "  خروشان بیامد ببهرام گفت   که کاهست لختی مرا در نهفت [MESRA_SEP] که تو در برابر خانه ی دار\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykc_K8HpC7LE",
        "outputId": "66225e01-2000-4da4-b57f-78d0324c8099"
      },
      "source": [
        "dict_bleu_mesra"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'حافظ': 0.20598327859442975, 'فردوسی': 0.15421370843466456}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI_d16xaaZAg"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vMPuPzD8v0D"
      },
      "source": [
        "text='گفتم غم تو دارم گفتا غمت سر آید'\r\n",
        "input_ids = tokenizer.encode(text, return_tensors='tf')# getting out output\r\n",
        "print(input_ids)\r\n",
        "beam_output = model.generate(\r\n",
        "  input_ids,\r\n",
        "  max_length = input_ids.shape[1]*5,\r\n",
        "  num_beams = 5,\r\n",
        "  temperature = 0.3,\r\n",
        "  no_repeat_ngram_size=3,\r\n",
        "  num_return_sequences=5\r\n",
        ")\r\n",
        "for output in  beam_output:\r\n",
        "  print(tokenizer.decode(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9mmuhFxIBpF"
      },
      "source": [
        "class my_dictionary(dict): \r\n",
        "  \r\n",
        "    # __init__ function \r\n",
        "    def __init__(self): \r\n",
        "        self = dict()      \r\n",
        "    # Function to add key:value \r\n",
        "    def add(self, key, value):\r\n",
        "        if key in self.keys(): \r\n",
        "          self[key].append( value)\r\n",
        "        else:\r\n",
        "          self[key]=[]\r\n",
        "          self[key].append( value)\r\n",
        "  \r\n",
        "# Main Function \r\n",
        "dict_poems_train = my_dictionary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoh6kSssEl4h"
      },
      "source": [
        "\r\n",
        "all_poems=[]\r\n",
        "with open('drive/MyDrive/poemDatasets_Fourth/train/AllPoemsTrain.txt', \"r\", encoding='utf-8') as f:\r\n",
        "  all_poems=f.readlines()\r\n",
        "for i in range(0,len(all_poems)-1 ,2):\r\n",
        "  all_poems[i]=all_poems[i].replace('\\n','')\r\n",
        "  all_poems[i+1]=all_poems[i+1].replace('\\n','')\r\n",
        "  dict_poems_train.add(all_poems[i],all_poems[i+1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCmNyy_6PDmm",
        "outputId": "e70d853b-b63b-48b6-c435-09010d975571"
      },
      "source": [
        "print(len(dict_poems_train.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8965MuDOtYb"
      },
      "source": [
        "count=0\r\n",
        "for key in dict_poems_train.keys():\r\n",
        "  print(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHOfNtP2sdG9",
        "outputId": "68e17a64-3721-4132-ec4e-0c14781d2575"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 24 20:19:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    34W / 250W |   8579MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}